#!/usr/bin/env python3
"""
éšå±¤å‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  - è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
30åˆ†æ¯ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã€1æ™‚é–“æ¯ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã€æ—¥æ¬¡å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ
"""

import os
import sys
import time
import json
import shutil
import threading
import schedule
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass
import zipfile
from jst_config import format_jst_datetime, format_jst_timestamp, format_jst_time

@dataclass
class BackupInfo:
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒ…å ±"""
    timestamp: str
    backup_type: str  # checkpoint, error, daily
    file_path: str
    size_mb: float
    description: str

class AutoCleanupManager:
    """è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.base_dir = Path(".claude_sub_agent")
        self.tmp_dir = self.base_dir / ".tmp"
        self.backup_dir = self.tmp_dir / "backups"
        self.checkpoint_dir = self.backup_dir / "checkpoints"
        self.error_backup_dir = self.backup_dir / "error_recovery"
        self.daily_backup_dir = self.backup_dir / "daily"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        for dir_path in [self.checkpoint_dir, self.error_backup_dir, self.daily_backup_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        self.config_file = self.base_dir / "cleanup_config.json"
        self.load_config()
        self.is_running = False
        self.scheduler_thread = None
        
    def load_config(self):
        """è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        default_config = {
            "checkpoint_interval_minutes": 30,
            "temp_cleanup_interval_minutes": 60,
            "daily_cleanup_hour": 3,  # åˆå‰3æ™‚
            "max_checkpoint_count": 10,
            "max_backup_age_days": 7,
            "auto_cleanup_enabled": True,
            "protected_dirs": [".git", "node_modules", ".ActivityReport", "docs", "specs"]
        }
        
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    self.config = json.load(f)
            except:
                self.config = default_config
        else:
            self.config = default_config
            self.save_config()
    
    def save_config(self):
        """è¨­å®šã‚’ä¿å­˜"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
    
    def create_checkpoint(self):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½œæˆï¼ˆ30åˆ†æ¯ï¼‰"""
        if not self.config["auto_cleanup_enabled"]:
            return
        
        timestamp = format_jst_timestamp()
        checkpoint_name = f"checkpoint_{timestamp}.zip"
        checkpoint_path = self.checkpoint_dir / checkpoint_name
        
        print(f"ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆä¸­... [{timestamp}]")
        
        try:
            # é‡è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            with zipfile.ZipFile(checkpoint_path, 'w', zipfile.ZIP_DEFLATED) as zf:
                for pattern in ["*.py", "*.js", "*.vue", "*.md", "*.json"]:
                    for file_path in Path(".").rglob(pattern):
                        # é™¤å¤–å¯¾è±¡ã‚’ã‚¹ã‚­ãƒƒãƒ—
                        if any(protected in str(file_path) for protected in self.config["protected_dirs"]):
                            continue
                        if ".tmp" in str(file_path) or ".git" in str(file_path):
                            continue
                        
                        try:
                            zf.write(file_path, file_path.relative_to(Path(".")))
                        except:
                            pass
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒ…å ±ã‚’è¨˜éŒ²
            backup_info = BackupInfo(
                timestamp=format_jst_datetime(),
                backup_type="checkpoint",
                file_path=str(checkpoint_path),
                size_mb=checkpoint_path.stat().st_size / (1024 * 1024),
                description="30åˆ†æ¯ã®è‡ªå‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ"
            )
            
            self._record_backup_info(backup_info)
            
            # å¤ã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤
            self._cleanup_old_checkpoints()
            
            print(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆå®Œäº†: {checkpoint_name} ({backup_info.size_mb:.2f}MB)")
            
        except Exception as e:
            print(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def cleanup_temp_files(self):
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆ1æ™‚é–“æ¯ï¼‰"""
        if not self.config["auto_cleanup_enabled"]:
            return
        
        print(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹... [{format_jst_time()}]")
        
        cleanup_targets = [
            ("*.tmp", 0),  # .tmpãƒ•ã‚¡ã‚¤ãƒ«ã¯å³å‰Šé™¤
            ("*.log", 24),  # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¯24æ™‚é–“å¾Œ
            ("*.bak", 48),  # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯48æ™‚é–“å¾Œ
            ("*~", 0),      # ã‚¨ãƒ‡ã‚£ã‚¿ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¯å³å‰Šé™¤
        ]
        
        deleted_count = 0
        freed_space = 0
        
        for pattern, hours_old in cleanup_targets:
            cutoff_time = datetime.now() - timedelta(hours=hours_old)
            
            for file_path in self.tmp_dir.rglob(pattern):
                try:
                    if datetime.fromtimestamp(file_path.stat().st_mtime) < cutoff_time:
                        file_size = file_path.stat().st_size
                        file_path.unlink()
                        deleted_count += 1
                        freed_space += file_size
                except:
                    pass
        
        # ç©ºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
        for dir_path in sorted(self.tmp_dir.rglob("*"), reverse=True):
            if dir_path.is_dir() and not any(dir_path.iterdir()):
                try:
                    dir_path.rmdir()
                except:
                    pass
        
        if deleted_count > 0:
            freed_mb = freed_space / (1024 * 1024)
            print(f"âœ… {deleted_count}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ ({freed_mb:.2f}MBè§£æ”¾)")
        else:
            print(f"âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¯¾è±¡ãªã—")
    
    def daily_cleanup(self):
        """æ—¥æ¬¡å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆåˆå‰3æ™‚ï¼‰"""
        if not self.config["auto_cleanup_enabled"]:
            return
        
        print(f"æ—¥æ¬¡å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹... [{format_jst_datetime()}]")
        
        # æ—¥æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
        self._create_daily_backup()
        
        # åŒ…æ‹¬çš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        cleanup_actions = [
            self._cleanup_analysis_cache,
            self._cleanup_agent_logs,
            self._cleanup_old_backups,
            self._cleanup_generated_docs,
            self._cleanup_workspace
        ]
        
        for action in cleanup_actions:
            try:
                action()
            except Exception as e:
                print(f"âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ãƒ¬ãƒãƒ¼ãƒˆ
        self._report_disk_usage()
        
        print(f"âœ… æ—¥æ¬¡å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
    
    def _create_daily_backup(self):
        """æ—¥æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d")
        backup_name = f"daily_backup_{timestamp}_JST.zip"
        backup_path = self.daily_backup_dir / backup_name
        
        if backup_path.exists():
            return  # ä»Šæ—¥ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯æ—¢ã«å­˜åœ¨
        
        try:
            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zf:
                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆé™¤å¤–å¯¾è±¡ã‚’é™¤ãï¼‰
                for file_path in Path(".").rglob("*"):
                    if file_path.is_file():
                        if any(skip in str(file_path) for skip in ['.git', '.tmp', '__pycache__']):
                            continue
                        try:
                            zf.write(file_path, file_path.relative_to(Path(".")))
                        except:
                            pass
            
            print(f"ğŸ’¾ æ—¥æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_name}")
        except Exception as e:
            print(f"âš ï¸ æ—¥æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _cleanup_old_checkpoints(self):
        """å¤ã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤"""
        checkpoints = sorted(self.checkpoint_dir.glob("checkpoint_*.zip"))
        
        if len(checkpoints) > self.config["max_checkpoint_count"]:
            for old_checkpoint in checkpoints[:-self.config["max_checkpoint_count"]]:
                old_checkpoint.unlink()
                print(f"ğŸ—‘ï¸ å¤ã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤: {old_checkpoint.name}")
    
    def _cleanup_old_backups(self):
        """å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤"""
        cutoff_date = datetime.now() - timedelta(days=self.config["max_backup_age_days"])
        
        for backup_dir in [self.daily_backup_dir, self.error_backup_dir]:
            for backup_file in backup_dir.glob("*.zip"):
                if datetime.fromtimestamp(backup_file.stat().st_mtime) < cutoff_date:
                    backup_file.unlink()
                    print(f"ğŸ—‘ï¸ å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤: {backup_file.name}")
    
    def _cleanup_analysis_cache(self):
        """è§£æã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        cache_dir = self.base_dir / "cache"
        if cache_dir.exists():
            cutoff_date = datetime.now() - timedelta(days=7)
            for cache_file in cache_dir.rglob("*.pkl"):
                if datetime.fromtimestamp(cache_file.stat().st_mtime) < cutoff_date:
                    cache_file.unlink()
    
    def _cleanup_agent_logs(self):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ­ã‚°ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        log_dir = self.tmp_dir / "agent_logs"
        if log_dir.exists():
            cutoff_date = datetime.now() - timedelta(days=3)
            for log_file in log_dir.rglob("*.log"):
                if datetime.fromtimestamp(log_file.stat().st_mtime) < cutoff_date:
                    log_file.unlink()
    
    def _cleanup_generated_docs(self):
        """ç”Ÿæˆã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        docs_dir = self.tmp_dir / "generated_docs"
        if docs_dir.exists():
            cutoff_date = datetime.now() - timedelta(days=7)
            for doc_file in docs_dir.rglob("*"):
                if doc_file.is_file() and datetime.fromtimestamp(doc_file.stat().st_mtime) < cutoff_date:
                    doc_file.unlink()
    
    def _cleanup_workspace(self):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæ¥­é ˜åŸŸã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        workspace_dir = self.tmp_dir / "agent_workspace"
        if workspace_dir.exists():
            for agent_dir in workspace_dir.iterdir():
                if agent_dir.is_dir():
                    # 24æ™‚é–“ä»¥ä¸Šå¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    cutoff_date = datetime.now() - timedelta(hours=24)
                    for file_path in agent_dir.rglob("*"):
                        if file_path.is_file() and datetime.fromtimestamp(file_path.stat().st_mtime) < cutoff_date:
                            file_path.unlink()
    
    def _report_disk_usage(self):
        """ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ã‚’ãƒ¬ãƒãƒ¼ãƒˆ"""
        total_size = 0
        file_count = 0
        
        for file_path in self.base_dir.rglob("*"):
            if file_path.is_file():
                total_size += file_path.stat().st_size
                file_count += 1
        
        size_mb = total_size / (1024 * 1024)
        print(f"ğŸ“Š ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡: {size_mb:.2f}MB ({file_count}ãƒ•ã‚¡ã‚¤ãƒ«)")
    
    def _record_backup_info(self, backup_info: BackupInfo):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒ…å ±ã‚’è¨˜éŒ²"""
        info_file = self.backup_dir / "backup_info.json"
        
        infos = []
        if info_file.exists():
            try:
                with open(info_file, 'r', encoding='utf-8') as f:
                    infos = json.load(f)
            except:
                pass
        
        infos.append({
            'timestamp': backup_info.timestamp,
            'backup_type': backup_info.backup_type,
            'file_path': backup_info.file_path,
            'size_mb': backup_info.size_mb,
            'description': backup_info.description
        })
        
        # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
        infos = infos[-100:]
        
        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(infos, f, indent=2, ensure_ascii=False)
    
    def create_error_backup(self, error_description: str = ""):
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        timestamp = format_jst_timestamp()
        backup_name = f"error_backup_{timestamp}.zip"
        backup_path = self.error_backup_dir / backup_name
        
        print(f"ğŸ†˜ ã‚¨ãƒ©ãƒ¼ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆä¸­...")
        
        try:
            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zf:
                # ç¾åœ¨ã®çŠ¶æ…‹ã‚’å…¨ã¦ä¿å­˜
                for file_path in Path(".").rglob("*"):
                    if file_path.is_file():
                        if ".git" in str(file_path):
                            continue
                        try:
                            zf.write(file_path, file_path.relative_to(Path(".")))
                        except:
                            pass
            
            backup_info = BackupInfo(
                timestamp=format_jst_datetime(),
                backup_type="error",
                file_path=str(backup_path),
                size_mb=backup_path.stat().st_size / (1024 * 1024),
                description=f"ã‚¨ãƒ©ãƒ¼å¾©æ—§ç”¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {error_description}"
            )
            
            self._record_backup_info(backup_info)
            
            print(f"âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå®Œäº†: {backup_name}")
            return backup_path
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—: {e}")
            return None
    
    def restore_from_backup(self, backup_path: Path) -> bool:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ"""
        print(f"ğŸ”„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒä¸­: {backup_path.name}")
        
        try:
            with zipfile.ZipFile(backup_path, 'r') as zf:
                zf.extractall(".")
            
            print(f"âœ… å¾©å…ƒå®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def start_scheduler(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹"""
        if self.is_running:
            return
        
        print("ğŸš€ è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼èµ·å‹•")
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®š
        schedule.every(self.config["checkpoint_interval_minutes"]).minutes.do(self.create_checkpoint)
        schedule.every(self.config["temp_cleanup_interval_minutes"]).minutes.do(self.cleanup_temp_files)
        schedule.every().day.at(f"{self.config['daily_cleanup_hour']:02d}:00").do(self.daily_cleanup)
        
        self.is_running = True
        self.scheduler_thread = threading.Thread(target=self._run_scheduler, daemon=True)
        self.scheduler_thread.start()
    
    def _run_scheduler(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’å®Ÿè¡Œ"""
        while self.is_running:
            schedule.run_pending()
            time.sleep(60)  # 1åˆ†æ¯ã«ãƒã‚§ãƒƒã‚¯
    
    def stop_scheduler(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’åœæ­¢"""
        self.is_running = False
        print("â¹ï¸ è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åœæ­¢")
    
    def manual_cleanup(self):
        """æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print("ğŸ”§ æ‰‹å‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ")
        self.cleanup_temp_files()
        self._cleanup_old_checkpoints()
        self._cleanup_old_backups()
        self._report_disk_usage()

def demo():
    """ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("\n" + "=" * 60)
    print("ğŸ§¹ è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢")
    print("=" * 60 + "\n")
    
    manager = AutoCleanupManager()
    
    # ç¾åœ¨ã®è¨­å®šè¡¨ç¤º
    print("ğŸ“‹ ç¾åœ¨ã®è¨­å®š:")
    print(f"  ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé–“éš”: {manager.config['checkpoint_interval_minutes']}åˆ†")
    print(f"  ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤é–“éš”: {manager.config['temp_cleanup_interval_minutes']}åˆ†")
    print(f"  æ—¥æ¬¡ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ™‚åˆ»: {manager.config['daily_cleanup_hour']}:00")
    print(f"  è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {'æœ‰åŠ¹' if manager.config['auto_cleanup_enabled'] else 'ç„¡åŠ¹'}")
    
    print("\n" + "-" * 40 + "\n")
    
    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆãƒ‡ãƒ¢
    print("ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆã€‘")
    manager.create_checkpoint()
    
    print("\n" + "-" * 40 + "\n")
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¢
    print("ã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã€‘")
    manager.cleanup_temp_files()
    
    print("\n" + "-" * 40 + "\n")
    
    # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ãƒ¬ãƒãƒ¼ãƒˆ
    manager._report_disk_usage()
    
    print("\nâœ… ãƒ‡ãƒ¢å®Œäº†\n")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse
    parser = argparse.ArgumentParser(description='è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ç®¡ç†')
    parser.add_argument('command', nargs='?', default='status',
                      choices=['status', 'start', 'stop', 'checkpoint', 'cleanup', 'demo'])
    parser.add_argument('--restore', help='ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ')
    
    args = parser.parse_args()
    
    manager = AutoCleanupManager()
    
    if args.restore:
        backup_path = Path(args.restore)
        if backup_path.exists():
            manager.restore_from_backup(backup_path)
        else:
            print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.restore}")
    elif args.command == 'status':
        print(f"è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {'æœ‰åŠ¹' if manager.config['auto_cleanup_enabled'] else 'ç„¡åŠ¹'}")
        manager._report_disk_usage()
    elif args.command == 'start':
        manager.start_scheduler()
        print("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚Ctrl+Cã§åœæ­¢ã—ã¾ã™ã€‚")
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            manager.stop_scheduler()
    elif args.command == 'stop':
        manager.config['auto_cleanup_enabled'] = False
        manager.save_config()
        print("è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ")
    elif args.command == 'checkpoint':
        manager.create_checkpoint()
    elif args.command == 'cleanup':
        manager.manual_cleanup()
    elif args.command == 'demo':
        demo()

if __name__ == "__main__":
    main()