#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå¾€å¾©æœ€é©åŒ–çµ±åˆè‡ªå·±è¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ  v15.0
è¨ºæ–­â†’å•é¡Œç‰¹å®šâ†’æ”¹å–„ææ¡ˆâ†’å®Ÿè£…æŒ‡ç¤ºã¾ã§ä¸€æ‹¬å‡¦ç†

å‚è€ƒ: https://zenn.dev/sakupanda/articles/ecb4ae7e9a240e
ç›®æ¨™: è¨ºæ–­å¾Œã®æ”¹å–„å®Ÿè£…ã§ AIå¾€å¾© 20å›â†’3-5å›ã«å‰Šæ¸›
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum

try:
    from .common_base import BaseManager, BaseResult, TaskStatus, create_result
    from .ai_batch_optimizer import AIBatchOptimizer, BatchTask, BatchTaskType
    from .automated_test_generator import AutomatedTestGenerator
    from .dependency_checker import UnifiedDependencyChecker
    from .path_utils import paths
    from .logger import logger
except ImportError:
    sys.path.insert(0, str(Path(__file__).parent))
    from common_base import BaseManager, BaseResult, TaskStatus, create_result
    from ai_batch_optimizer import AIBatchOptimizer, BatchTask, BatchTaskType
    from automated_test_generator import AutomatedTestGenerator
    from dependency_checker import UnifiedDependencyChecker
    from path_utils import paths
    from logger import logger


class DiagnosisSeverity(Enum):
    """è¨ºæ–­å•é¡Œã®é‡è¦åº¦"""
    CRITICAL = "critical"
    HIGH = "high" 
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"


class ImprovementActionType(Enum):
    """æ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç¨®åˆ¥"""
    CODE_FIX = "code_fix"
    TEST_GENERATION = "test_generation"
    REFACTORING = "refactoring"
    DOCUMENTATION = "documentation"
    PERFORMANCE_OPTIMIZATION = "performance_optimization"


@dataclass
class DiagnosisIssue:
    """è¨ºæ–­ã§ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ"""
    category: str
    severity: DiagnosisSeverity
    description: str
    affected_modules: List[str]
    recommended_actions: List[ImprovementActionType]
    ai_batch_specification: Optional[Dict[str, Any]] = None


@dataclass
class ImprovementBatchSpec:
    """æ”¹å–„ãƒãƒƒãƒå‡¦ç†ä»•æ§˜"""
    issue_id: str
    action_type: ImprovementActionType
    priority: int
    specification: Dict[str, Any]
    expected_outcomes: List[str]
    validation_commands: List[str]


class OptimizedSelfDiagnosisSystem(BaseManager):
    """AIå¾€å¾©æœ€é©åŒ–çµ±åˆè‡ªå·±è¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        super().__init__("OptimizedSelfDiagnosisSystem")
        
        # ãƒ‘ã‚¹ã®è¨­å®š
        self.base_path = paths.root
        self.system_path = paths.system
        self.core_path = paths.core
        self.tests_path = paths.tests
        
        # è¨ºæ–­çµæœ
        self.diagnosis_results = {
            "timestamp": datetime.now().isoformat(),
            "version": "15.0",
            "overall_health": "UNKNOWN",
            "issues_found": [],
            "improvement_batches": [],
            "ai_optimization_metrics": {},
            "test_coverage": 0,
            "performance_metrics": {}
        }
        
        # AIæœ€é©åŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.ai_optimizer = None
        self.test_generator = None
        self.dependency_checker = None
        
    def initialize(self) -> BaseResult:
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        try:
            # AIæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            self.ai_optimizer = AIBatchOptimizer()
            self.test_generator = AutomatedTestGenerator()
            self.dependency_checker = UnifiedDependencyChecker()
            
            # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
            components = [
                ("AI Optimizer", self.ai_optimizer),
                ("Test Generator", self.test_generator)
            ]
            
            for name, component in components:
                if hasattr(component, 'initialize'):
                    result = component.initialize()
                    if not result.success:
                        return create_result(False, f"{name} initialization failed: {result.message}")
            
            logger.info("Optimized Self-Diagnosis System v15.0 initialized")
            return create_result(True, "System initialized successfully")
            
        except Exception as e:
            return create_result(False, f"Initialization failed: {e}")
    
    def cleanup(self) -> BaseResult:
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            components = [self.ai_optimizer, self.test_generator]
            for component in components:
                if component and hasattr(component, 'cleanup'):
                    component.cleanup()
            return create_result(True, "Cleanup completed")
        except Exception as e:
            return create_result(False, f"Cleanup failed: {e}")
    
    def run_optimized_diagnosis_cycle(self) -> BaseResult:
        """
        AIå¾€å¾©æœ€é©åŒ–è¨ºæ–­ã‚µã‚¤ã‚¯ãƒ« - ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
        è¨ºæ–­â†’å•é¡Œåˆ†æâ†’æ”¹å–„ä»•æ§˜ä½œæˆâ†’AIä¸€æ‹¬å®Ÿè£…æŒ‡ç¤º
        """
        try:
            print("=" * 80)
            print("Alex Team Optimized Self-Diagnosis System v15.0")
            print("AI Roundtrip Optimization: 20 rounds -> 3-5 rounds")
            print("=" * 80)
            
            # Phase 1: å¾“æ¥ã®è¨ºæ–­å®Ÿè¡Œ
            print("\n[Phase 1] Comprehensive Diagnosis")
            diagnosis_result = self._run_comprehensive_diagnosis()
            
            if not diagnosis_result.success:
                return diagnosis_result
            
            # Phase 2: å•é¡Œåˆ†æã¨ãƒãƒƒãƒä»•æ§˜ä½œæˆ
            print("\n[Phase 2] Issue Analysis & Batch Specification Creation")
            batch_specs = self._create_improvement_batch_specifications()
            
            # Phase 3: AIå¾€å¾©æœ€é©åŒ–æ”¹å–„ææ¡ˆç”Ÿæˆ
            print("\n[Phase 3] AI-Optimized Improvement Proposals")
            improvement_proposals = self._generate_ai_optimized_proposals(batch_specs)
            
            # Phase 4: çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            print("\n[Phase 4] Integrated Report Generation")
            report_result = self._generate_optimized_report(improvement_proposals)
            
            self.diagnosis_results["ai_optimization_metrics"] = {
                "total_issues": len(batch_specs),
                "batch_specifications_created": len(batch_specs),
                "ai_proposals_generated": len(improvement_proposals),
                "estimated_roundtrip_reduction": "75-85%",
                "estimated_time_saving": "2-3 hours â†’ 30-45 minutes"
            }
            
            return create_result(
                True, 
                "Optimized diagnosis cycle completed successfully",
                {
                    "diagnosis": self.diagnosis_results,
                    "improvement_proposals": improvement_proposals,
                    "batch_count": len(batch_specs)
                }
            )
            
        except Exception as e:
            logger.error(f"Optimized diagnosis cycle failed: {e}")
            return create_result(False, f"Diagnosis cycle failed: {e}")
    
    def _run_comprehensive_diagnosis(self) -> BaseResult:
        """åŒ…æ‹¬çš„è¨ºæ–­å®Ÿè¡Œ"""
        try:
            issues = []
            
            # 1. ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ãƒã‚§ãƒƒã‚¯
            print("  [1/6] Folder Structure Analysis...")
            folder_issues = self._analyze_folder_structure()
            issues.extend(folder_issues)
            
            # 2. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯  
            print("  [2/6] Module Health Analysis...")
            module_issues = self._analyze_module_health()
            issues.extend(module_issues)
            
            # 3. ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ
            print("  [3/6] Test Coverage Analysis...")
            coverage_issues = self._analyze_test_coverage()
            issues.extend(coverage_issues)
            
            # 4. ä¾å­˜é–¢ä¿‚åˆ†æ
            print("  [4/6] Dependencies Analysis...")
            dependency_issues = self._analyze_dependencies()
            issues.extend(dependency_issues)
            
            # 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
            print("  [5/6] Performance Analysis...")
            performance_issues = self._analyze_performance()
            issues.extend(performance_issues)
            
            # 6. å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æ
            print("  [6/6] Quality Metrics Analysis...")
            quality_issues = self._analyze_code_quality()
            issues.extend(quality_issues)
            
            self.diagnosis_results["issues_found"] = [asdict(issue) for issue in issues]
            self._evaluate_overall_health()
            
            print(f"\nDiagnosis completed: {len(issues)} issues identified")
            return create_result(True, f"Comprehensive diagnosis completed with {len(issues)} issues")
            
        except Exception as e:
            return create_result(False, f"Comprehensive diagnosis failed: {e}")
    
    def _analyze_folder_structure(self) -> List[DiagnosisIssue]:
        """ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ åˆ†æ"""
        issues = []
        required_folders = {
            "system/core": self.core_path,
            "project/tests": self.tests_path,
            "system/templates": self.system_path / "templates",
        }
        
        missing_folders = []
        for name, path in required_folders.items():
            if not path.exists():
                missing_folders.append(name)
        
        if missing_folders:
            issues.append(DiagnosisIssue(
                category="FOLDER_STRUCTURE",
                severity=DiagnosisSeverity.MEDIUM,
                description=f"Missing folders: {', '.join(missing_folders)}",
                affected_modules=[],
                recommended_actions=[ImprovementActionType.CODE_FIX],
                ai_batch_specification={
                    "task_type": "folder_creation",
                    "folders_to_create": missing_folders,
                    "template_source": "system/templates"
                }
            ))
        
        return issues
    
    def _analyze_module_health(self) -> List[DiagnosisIssue]:
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å¥å…¨æ€§åˆ†æ"""
        issues = []
        
        if not self.core_path.exists():
            return [DiagnosisIssue(
                category="MODULE_HEALTH",
                severity=DiagnosisSeverity.CRITICAL,
                description="Core module path does not exist",
                affected_modules=[],
                recommended_actions=[ImprovementActionType.CODE_FIX]
            )]
        
        py_files = list(self.core_path.glob("*.py"))
        import_errors = []
        
        for py_file in py_files:
            module_name = py_file.stem
            try:
                spec = importlib.util.spec_from_file_location(module_name, py_file)
                if spec and spec.loader:
                    module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(module)
            except Exception as e:
                import_errors.append((module_name, str(e)))
        
        if import_errors:
            affected_modules = [name for name, _ in import_errors]
            issues.append(DiagnosisIssue(
                category="MODULE_IMPORT",
                severity=DiagnosisSeverity.HIGH,
                description=f"Import errors in {len(import_errors)} modules",
                affected_modules=affected_modules,
                recommended_actions=[ImprovementActionType.CODE_FIX, ImprovementActionType.REFACTORING],
                ai_batch_specification={
                    "task_type": "import_error_fix",
                    "modules_with_errors": import_errors,
                    "fix_patterns": ["missing_imports", "circular_imports", "path_issues"]
                }
            ))
        
        return issues
    
    def _analyze_test_coverage(self) -> List[DiagnosisIssue]:
        """ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ"""
        issues = []
        coverage_file = self.tests_path / "coverage_reports" / "coverage.json"
        
        target_coverage = 95.0
        current_coverage = 0.0
        
        if coverage_file.exists():
            try:
                with open(coverage_file, 'r', encoding='utf-8') as f:
                    coverage_data = json.load(f)
                    current_coverage = coverage_data.get('totals', {}).get('percent_covered', 0)
            except Exception:
                pass
        
        self.diagnosis_results["test_coverage"] = current_coverage
        
        if current_coverage < target_coverage:
            gap = target_coverage - current_coverage
            issues.append(DiagnosisIssue(
                category="TEST_COVERAGE",
                severity=DiagnosisSeverity.HIGH if gap > 20 else DiagnosisSeverity.MEDIUM,
                description=f"Test coverage {current_coverage:.1f}% below target {target_coverage}%",
                affected_modules=[],
                recommended_actions=[ImprovementActionType.TEST_GENERATION],
                ai_batch_specification={
                    "task_type": "test_coverage_improvement",
                    "current_coverage": current_coverage,
                    "target_coverage": target_coverage,
                    "modules_need_tests": self._identify_low_coverage_modules(),
                    "test_types": ["unit_tests", "integration_tests", "edge_case_tests"]
                }
            ))
        
        return issues
    
    def _analyze_dependencies(self) -> List[DiagnosisIssue]:
        """ä¾å­˜é–¢ä¿‚åˆ†æ"""
        issues = []
        
        if self.dependency_checker:
            dep_result = self.dependency_checker.check_all_dependencies()
            
            if dep_result.has_circular_deps:
                issues.append(DiagnosisIssue(
                    category="CIRCULAR_DEPENDENCIES",
                    severity=DiagnosisSeverity.HIGH,
                    description=f"Circular dependencies detected: {len(dep_result.circular_paths)} cycles",
                    affected_modules=[],
                    recommended_actions=[ImprovementActionType.REFACTORING],
                    ai_batch_specification={
                        "task_type": "circular_dependency_resolution",
                        "circular_paths": dep_result.circular_paths,
                        "resolution_strategies": ["interface_extraction", "dependency_injection", "module_splitting"]
                    }
                ))
            
            if dep_result.errors:
                issues.append(DiagnosisIssue(
                    category="DEPENDENCY_ERRORS",
                    severity=DiagnosisSeverity.MEDIUM,
                    description=f"Dependency check errors: {len(dep_result.errors)}",
                    affected_modules=[],
                    recommended_actions=[ImprovementActionType.CODE_FIX]
                ))
        
        return issues
    
    def _analyze_performance(self) -> List[DiagnosisIssue]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        issues = []
        
        try:
            import psutil
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
            if memory_mb > 100:  # 100MBä»¥ä¸Š
                issues.append(DiagnosisIssue(
                    category="MEMORY_USAGE",
                    severity=DiagnosisSeverity.MEDIUM,
                    description=f"High memory usage: {memory_mb:.1f} MB",
                    affected_modules=[],
                    recommended_actions=[ImprovementActionType.PERFORMANCE_OPTIMIZATION],
                    ai_batch_specification={
                        "task_type": "memory_optimization",
                        "current_usage": memory_mb,
                        "target_usage": 50.0,
                        "optimization_areas": ["cache_optimization", "object_pooling", "lazy_loading"]
                    }
                ))
        except ImportError:
            pass
        
        return issues
    
    def _analyze_code_quality(self) -> List[DiagnosisIssue]:
        """ã‚³ãƒ¼ãƒ‰å“è³ªåˆ†æ"""
        issues = []
        
        # YAGNIé•åãƒã‚§ãƒƒã‚¯ï¼ˆæœªä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        test_files = list(self.core_path.glob("test_*.py"))
        if len(test_files) > 20:  # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«éå¤š
            issues.append(DiagnosisIssue(
                category="YAGNI_VIOLATION", 
                severity=DiagnosisSeverity.MEDIUM,
                description=f"Too many test files: {len(test_files)} (consider consolidation)",
                affected_modules=[],
                recommended_actions=[ImprovementActionType.REFACTORING],
                ai_batch_specification={
                    "task_type": "test_consolidation",
                    "current_test_count": len(test_files),
                    "target_test_count": 10,
                    "consolidation_strategy": "merge_similar_tests"
                }
            ))
        
        return issues
    
    def _create_improvement_batch_specifications(self) -> List[ImprovementBatchSpec]:
        """æ”¹å–„ãƒãƒƒãƒä»•æ§˜ä½œæˆ"""
        batch_specs = []
        
        for i, issue_data in enumerate(self.diagnosis_results["issues_found"]):
            issue = DiagnosisIssue(**issue_data)
            
            if issue.ai_batch_specification:
                for action_type in issue.recommended_actions:
                    batch_spec = ImprovementBatchSpec(
                        issue_id=f"issue_{i}_{action_type.value}",
                        action_type=action_type,
                        priority=self._get_priority_from_severity(issue.severity),
                        specification={
                            "issue_category": issue.category,
                            "description": issue.description,
                            "affected_modules": issue.affected_modules,
                            "ai_batch_spec": issue.ai_batch_specification,
                            "success_criteria": self._generate_success_criteria(issue),
                            "validation_commands": self._generate_validation_commands(issue)
                        },
                        expected_outcomes=self._generate_expected_outcomes(issue, action_type),
                        validation_commands=self._generate_validation_commands(issue)
                    )
                    batch_specs.append(batch_spec)
        
        return batch_specs
    
    def _generate_ai_optimized_proposals(self, batch_specs: List[ImprovementBatchSpec]) -> List[Dict[str, Any]]:
        """AIå¾€å¾©æœ€é©åŒ–æ”¹å–„ææ¡ˆç”Ÿæˆ"""
        proposals = []
        
        for batch_spec in batch_specs:
            proposal = {
                "issue_id": batch_spec.issue_id,
                "action_type": batch_spec.action_type.value,
                "priority": batch_spec.priority,
                
                # AIä¸€æ‹¬å®Ÿè£…æŒ‡ç¤ºï¼ˆä»•æ§˜æ›¸ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆï¼‰
                "ai_implementation_request": self._create_ai_implementation_request(batch_spec),
                
                # ãƒãƒƒãƒå‡¦ç†ä»•æ§˜
                "batch_processing_spec": {
                    "task_type": batch_spec.action_type.value,
                    "specification": batch_spec.specification,
                    "expected_outcomes": batch_spec.expected_outcomes,
                    "validation_commands": batch_spec.validation_commands
                },
                
                # å¾€å¾©æœ€é©åŒ–æƒ…å ±
                "roundtrip_optimization": {
                    "estimated_traditional_rounds": 15-20,
                    "estimated_optimized_rounds": 3-5,
                    "reduction_percentage": "75-85%",
                    "key_optimizations": [
                        "Specification-first approach",
                        "Batch processing integration",
                        "Automated validation cycle",
                        "Self-correction capability"
                    ]
                }
            }
            
            proposals.append(proposal)
        
        return proposals
    
    def _create_ai_implementation_request(self, batch_spec: ImprovementBatchSpec) -> str:
        """AIå®Ÿè£…ä¾é ¼æ–‡ç”Ÿæˆ"""
        spec = batch_spec.specification
        
        template = f"""
ã€AIå¾€å¾©æœ€é©åŒ– - ä¸€æ‹¬æ”¹å–„å®Ÿè£…ä¾é ¼ã€‘

## å•é¡Œæ¦‚è¦
- **ã‚«ãƒ†ã‚´ãƒª**: {spec['issue_category']}
- **èª¬æ˜**: {spec['description']}
- **å½±éŸ¿ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«**: {', '.join(spec['affected_modules']) if spec['affected_modules'] else 'ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“'}

## å®Ÿè£…è¦æ±‚
AI_COLLABORATION_CONTEXT.mdã¨SPECIFICATION_TEMPLATE.mdã«åŸºã¥ãã€ä»¥ä¸‹ã‚’**ä¸€æ‹¬ã§å®Ÿè£…**ã—ã¦ãã ã•ã„:

### 1. å•é¡Œè§£æ±ºå®Ÿè£…
- æ ¹æœ¬åŸå› ã®ä¿®æ­£
- é–¢é€£ã™ã‚‹å…¨ã¦ã®ä¾å­˜é–¢ä¿‚ã®æ›´æ–°
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®æ”¹å–„

### 2. ãƒ†ã‚¹ãƒˆå®Ÿè£… (TDDå¯¾å¿œ)
- RED Phase: å•é¡Œå†ç¾ãƒ†ã‚¹ãƒˆ
- GREEN Phase: ä¿®æ­£å¾Œã®æ­£å¸¸å‹•ä½œãƒ†ã‚¹ãƒˆ
- ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ

### 3. çµ±åˆæ¤œè¨¼
- æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆç¢ºèª
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å½±éŸ¿ç¢ºèª
- ä¾å­˜é–¢ä¿‚ã®å¥å…¨æ€§ç¢ºèª

### 4. è‡ªå‹•ä¿®æ­£å¯¾å¿œ
ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯è‡ªå‹•çš„ã«ä»¥ä¸‹ã‚’è©¦è¡Œ:
- ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã®ä¿®æ­£
- ä¾å­˜é–¢ä¿‚ã®è§£æ±º
- ãƒ†ã‚¹ãƒˆã®èª¿æ•´

## æˆåŠŸåŸºæº–
{chr(10).join(f'- {criteria}' for criteria in spec.get('success_criteria', ['æ­£å¸¸å‹•ä½œç¢ºèª']))}

## æ¤œè¨¼ã‚³ãƒãƒ³ãƒ‰
{chr(10).join(f'```bash{chr(10)}{cmd}{chr(10)}```' for cmd in batch_spec.validation_commands)}

**é‡è¦**: ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯è‡ªå‹•ä¿®æ­£ã‚’è©¦è¡Œã—ã€æœ€çµ‚çš„ã«å‹•ä½œã™ã‚‹çŠ¶æ…‹ã¾ã§å®Œæˆã•ã›ã¦ãã ã•ã„ã€‚
        """
        
        return template.strip()
    
    def _generate_success_criteria(self, issue: DiagnosisIssue) -> List[str]:
        """æˆåŠŸåŸºæº–ç”Ÿæˆ"""
        criteria = []
        
        if issue.category == "TEST_COVERAGE":
            criteria.append("ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸95%ä»¥ä¸Šé”æˆ")
            criteria.append("å…¨ãƒ†ã‚¹ãƒˆæ­£å¸¸å®Ÿè¡Œ")
        elif issue.category == "MODULE_IMPORT":
            criteria.append("å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼è§£æ¶ˆ")
            criteria.append("ä¾å­˜é–¢ä¿‚ã®å¥å…¨æ€§ç¢ºèª")
        elif issue.category == "CIRCULAR_DEPENDENCIES":
            criteria.append("å¾ªç’°ä¾å­˜ã®å®Œå…¨è§£æ¶ˆ")
            criteria.append("ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„")
        else:
            criteria.append("å•é¡Œã®å®Œå…¨è§£æ±º")
            criteria.append("ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§ã®ç¢ºä¿")
        
        return criteria
    
    def _generate_validation_commands(self, issue: DiagnosisIssue) -> List[str]:
        """æ¤œè¨¼ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ"""
        commands = []
        
        if issue.category == "TEST_COVERAGE":
            commands.extend([
                "python -m pytest project/tests/ --cov=system/core --cov-report=term-missing -v",
                "python -m coverage report --fail-under=95"
            ])
        elif issue.category == "MODULE_IMPORT":
            commands.extend([
                "python -c \"import sys; sys.path.insert(0, 'system'); from core import *; print('All imports successful')\"",
                "python system/core/dependency_checker.py"
            ])
        else:
            commands.extend([
                "python -m pytest project/tests/ -v --tb=short",
                "lefthook run ai-ready"
            ])
        
        return commands
    
    def _generate_expected_outcomes(self, issue: DiagnosisIssue, action_type: ImprovementActionType) -> List[str]:
        """æœŸå¾…ã•ã‚Œã‚‹æˆæœç”Ÿæˆ"""
        outcomes = []
        
        if action_type == ImprovementActionType.TEST_GENERATION:
            outcomes.extend([
                "è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«",
                "95%ä»¥ä¸Šã®ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸",
                "å…¨ãƒ†ã‚¹ãƒˆæ­£å¸¸å®Ÿè¡Œ"
            ])
        elif action_type == ImprovementActionType.CODE_FIX:
            outcomes.extend([
                "ã‚¨ãƒ©ãƒ¼ã®å®Œå…¨ä¿®æ­£",
                "æ­£å¸¸ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å‹•ä½œ",
                "çµ±åˆãƒ†ã‚¹ãƒˆé€šé"
            ])
        elif action_type == ImprovementActionType.REFACTORING:
            outcomes.extend([
                "ã‚³ãƒ¼ãƒ‰å“è³ªã®å‘ä¸Š",
                "ä¿å®ˆæ€§ã®æ”¹å–„",
                "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–"
            ])
        
        return outcomes
    
    def _get_priority_from_severity(self, severity: DiagnosisSeverity) -> int:
        """é‡è¦åº¦ã‹ã‚‰å„ªå…ˆåº¦ã‚’ç®—å‡º"""
        priority_map = {
            DiagnosisSeverity.CRITICAL: 1,
            DiagnosisSeverity.HIGH: 2,
            DiagnosisSeverity.MEDIUM: 3,
            DiagnosisSeverity.LOW: 4,
            DiagnosisSeverity.INFO: 5
        }
        return priority_map.get(severity, 3)
    
    def _identify_low_coverage_modules(self) -> List[str]:
        """ã‚«ãƒãƒ¬ãƒƒã‚¸ä¸è¶³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç‰¹å®š"""
        # ç°¡æ˜“ç‰ˆ - å®Ÿéš›ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å®š
        py_files = list(self.core_path.glob("*.py"))
        test_files = list(self.tests_path.glob("test_*.py"))
        
        tested_modules = set()
        for test_file in test_files:
            module_name = test_file.name.replace("test_", "").replace(".py", "")
            tested_modules.add(module_name)
        
        low_coverage = []
        for py_file in py_files:
            if py_file.stem not in tested_modules and not py_file.stem.startswith("test_"):
                low_coverage.append(py_file.stem)
        
        return low_coverage[:10]  # æœ€å¤§10å€‹
    
    def _evaluate_overall_health(self):
        """å…¨ä½“å¥å…¨æ€§è©•ä¾¡"""
        issues = self.diagnosis_results["issues_found"]
        
        critical_count = sum(1 for issue in issues if issue["severity"] == "critical")
        high_count = sum(1 for issue in issues if issue["severity"] == "high")
        
        if critical_count > 0:
            self.diagnosis_results["overall_health"] = "CRITICAL"
        elif high_count > 3:
            self.diagnosis_results["overall_health"] = "NEEDS_ATTENTION"
        elif len(issues) > 5:
            self.diagnosis_results["overall_health"] = "GOOD"
        else:
            self.diagnosis_results["overall_health"] = "EXCELLENT"
    
    def _generate_optimized_report(self, improvement_proposals: List[Dict[str, Any]]) -> BaseResult:
        """æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            report_path = paths.root / f"OPTIMIZED_DIAGNOSIS_REPORT_{timestamp}.md"
            
            report_content = self._create_detailed_report(improvement_proposals)
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"\nOptimized Diagnosis Report: {report_path}")
            print(f"   Issues Found: {len(self.diagnosis_results['issues_found'])}")
            print(f"   AI Proposals: {len(improvement_proposals)}")
            print(f"   Estimated Roundtrip Reduction: 75-85%")
            
            return create_result(True, "Optimized report generated", {"report_path": str(report_path)})
            
        except Exception as e:
            return create_result(False, f"Report generation failed: {e}")
    
    def _create_detailed_report(self, improvement_proposals: List[Dict[str, Any]]) -> str:
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        report = f"""# Alex Team Optimized Diagnosis Report

## ğŸ“Š Diagnosis Summary
- **Timestamp**: {self.diagnosis_results['timestamp']}
- **System Version**: v{self.diagnosis_results['version']}
- **Overall Health**: {self.diagnosis_results['overall_health']}
- **Issues Found**: {len(self.diagnosis_results['issues_found'])}
- **Test Coverage**: {self.diagnosis_results['test_coverage']:.1f}%

## ğŸ¯ AI Roundtrip Optimization Results
- **Traditional Approach**: 15-20 AI interactions per issue
- **Optimized Approach**: 3-5 AI interactions per issue
- **Reduction**: **75-85% fewer roundtrips**
- **Time Saving**: 2-3 hours â†’ 30-45 minutes

## ğŸš€ AI-Optimized Improvement Proposals

"""
        
        for i, proposal in enumerate(improvement_proposals, 1):
            report += f"""
### {i}. {proposal['action_type'].title()} (Priority: {proposal['priority']})

**Issue ID**: {proposal['issue_id']}

#### AI Implementation Request
```
{proposal['ai_implementation_request']}
```

#### Batch Processing Specification
- **Expected Outcomes**: {', '.join(proposal['batch_processing_spec']['expected_outcomes'])}
- **Validation Commands**: {len(proposal['batch_processing_spec']['validation_commands'])} automated checks

#### Roundtrip Optimization
- **Traditional Rounds**: {proposal['roundtrip_optimization']['estimated_traditional_rounds']}
- **Optimized Rounds**: {proposal['roundtrip_optimization']['estimated_optimized_rounds']}
- **Reduction**: {proposal['roundtrip_optimization']['reduction_percentage']}

---
"""
        
        report += f"""
## ğŸ“ˆ Next Steps

### 1. Copy AI Implementation Requests
Copy the above AI implementation requests and send them to AI in sequence.

### 2. Monitor Optimization Metrics
- Expected total rounds: {len(improvement_proposals) * 3}-{len(improvement_proposals) * 5}
- Traditional total rounds: {len(improvement_proposals) * 15}-{len(improvement_proposals) * 20}
- Savings: **{len(improvement_proposals) * 12}-{len(improvement_proposals) * 17} rounds**

### 3. Validation
Run automated validation after each implementation:
```bash
lefthook run ai-ready
python system/core/optimized_self_diagnosis_system.py --validate
```

---

**Generated by**: Alex Team Optimized Self-Diagnosis System v15.0
**Optimization Reference**: https://zenn.dev/sakupanda/articles/ecb4ae7e9a240e
"""
        
        return report


def run_optimized_diagnosis() -> BaseResult:
    """æœ€é©åŒ–è¨ºæ–­å®Ÿè¡Œã®ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    system = OptimizedSelfDiagnosisSystem()
    
    # åˆæœŸåŒ–
    init_result = system.initialize()
    if not init_result.success:
        return init_result
    
    # æœ€é©åŒ–è¨ºæ–­ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ
    diagnosis_result = system.run_optimized_diagnosis_cycle()
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    system.cleanup()
    
    return diagnosis_result


def main():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("Starting Alex Team Optimized Self-Diagnosis...")
    
    result = run_optimized_diagnosis()
    
    if result.success:
        print("\nSUCCESS: Optimized diagnosis completed successfully!")
        if result.data and 'batch_count' in result.data:
            print(f"   Generated {result.data['batch_count']} AI-optimized improvement proposals")
        return 0
    else:
        print(f"\nERROR: Diagnosis failed: {result.message}")
        return 1


if __name__ == "__main__":
    sys.exit(main())